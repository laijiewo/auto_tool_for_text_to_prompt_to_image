from openai import OpenAI
import json
import os

# ========== é…ç½® ==========

# ä½ çš„ OpenAI API Keyï¼ˆå¯æ›¿æ¢ä¸ºç¯å¢ƒå˜é‡æˆ–ä»æ–‡ä»¶è¯»å–ï¼‰
client = OpenAI(api_key="key")

MEMORY_FILE = "memory.json"

# ========== å·¥å…·å‡½æ•° ==========


def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_memory(memory):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory, f, ensure_ascii=False, indent=2)


def build_memory_prompt(memory):
    return f"""
ä½ æ­£åœ¨å’Œç”¨æˆ·å¯¹è¯ï¼Œè¯·è®°ä½ä»¥ä¸‹ä¿¡æ¯ï¼š
- ç”¨æˆ·å§“åï¼š{memory.get('name', 'æœªçŸ¥')}
- ç”¨æˆ·åå¥½ï¼š{memory.get('preferences', 'æœªçŸ¥')}
- å¤‡æ³¨ï¼š{memory.get('notes', '')}
"""


def update_memory(memory, new_note):
    if new_note:
        memory["notes"] += f" {new_note}"
        save_memory(memory)


# ========== èŠå¤©ä¸»å‡½æ•° ==========


def chat():
    memory = load_memory()
    memory_intro = build_memory_prompt(memory)

    print("ğŸ’¬ è¯·è¾“å…¥ç”¨æˆ·æé—®ï¼Œè¾“å…¥ 'exit' é€€å‡ºï¼š")
    messages = [{"role": "system", "content": memory_intro}]

    while True:
        user_input = input("ğŸ‘¤ ä½ ï¼š")
        if user_input.lower() == "exit":
            break

        messages.append({"role": "user", "content": user_input})

        # ä¸ GPT äº¤äº’
        response = client.chat.completions.create(model="gpt-4", messages=messages)

        reply = response.choices[0].message.content
        print(f"ğŸ¤– GPTï¼š{reply}")

        messages.append({"role": "assistant", "content": reply})

        # ç®€å•ç¤ºä¾‹ï¼šè‹¥ç”¨æˆ·è¾“å…¥â€œè®°ä½æˆ‘å–œæ¬¢ç‹—â€ï¼Œå°±è¿½åŠ åå¥½
        if "è®°ä½" in user_input and "å–œæ¬¢" in user_input:
            update_memory(memory, user_input.replace("è®°ä½", "").strip())


# ========== å¯åŠ¨ ==========

if __name__ == "__main__":
    chat()
